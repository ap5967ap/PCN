{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Jupyter environment detected. Enabling Open3D WebVisualizer.\n",
      "[Open3D INFO] WebRTC GUI backend enabled.\n",
      "[Open3D INFO] WebRTCWindowSystem: HTTP handshake server disabled.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import random\n",
    "import numpy as np\n",
    "import open3d as o3d\n",
    "import torch.utils.data as data\n",
    "import torch\n",
    "import torch.optim as Optim\n",
    "from torch.utils.data.dataloader import DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.backends.cudnn.benchmark = True\n",
    "num_workers = 8\n",
    "batch_size = 32\n",
    "device=\"cuda:0\"\n",
    "LR=0.0001\n",
    "epochs=100\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_path_partial=rf\"/home/ananthakrishnak/pe/pcn-pytorch/data/PCN/train/partial/02958343\"\n",
    "train_path_complete=rf\"/home/ananthakrishnak/pe/pcn-pytorch/data/PCN/train/complete/02958343\"\n",
    "\n",
    "valid_path_partial=rf\"/home/ananthakrishnak/pe/pcn-pytorch/data/PCN/valid/partial/02958343\"\n",
    "valid_path_complete=rf\"/home/ananthakrishnak/pe/pcn-pytorch/data/PCN/valid/complete/02958343\"\n",
    "\n",
    "test_path_partial=rf\"/home/ananthakrishnak/pe/pcn-pytorch/data/PCN/test/partial/02958343\"\n",
    "test_path_complete=rf\"/home/ananthakrishnak/pe/pcn-pytorch/data/PCN/test/complete/02958343\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class shapenet_data_loader(data.Dataset):\n",
    "    def __init__(self, x_path, y_path, split):\n",
    "        self.x_path = x_path\n",
    "        self.y_path = y_path\n",
    "        self.split = split\n",
    "        self.partial_paths, self.complete_paths = self._load_data()\n",
    "\n",
    "    def _load_data(self):\n",
    "        lines=os.listdir(self.y_path)\n",
    "        partial_paths, complete_paths = list(), list()\n",
    "        for model_id in lines:\n",
    "            if self.split == 'train':\n",
    "                a=model_id.split('.ply')[0]\n",
    "                partial_paths.append(os.path.join(self.x_path, a + '_{}.ply'))\n",
    "            else:\n",
    "                partial_paths.append(os.path.join(self.x_path, model_id))\n",
    "            complete_paths.append(os.path.join(self.y_path, model_id ))\n",
    "        return partial_paths, complete_paths\n",
    "    \n",
    "    def read_point_cloud(self, path):\n",
    "        pc = o3d.io.read_point_cloud(path)\n",
    "        return np.array(pc.points, np.float32)\n",
    "    \n",
    "    def random_sample(self, pc, n):\n",
    "        if pc.shape[0] == 0:\n",
    "            raise ValueError(\"Point cloud is empty, cannot sample points.\")\n",
    "        idx = np.random.permutation(pc.shape[0])\n",
    "        if idx.shape[0] < n:\n",
    "            idx = np.concatenate([idx, np.random.randint(pc.shape[0], size=n-pc.shape[0])])\n",
    "        return pc[idx[:n]]\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        if self.split == 'train':\n",
    "            partial_path = self.partial_paths[index].format(random.randint(0, 7))\n",
    "        else:\n",
    "            partial_path = self.partial_paths[index]\n",
    "        complete_path = self.complete_paths[index]\n",
    "        partial_pc = self.random_sample(self.read_point_cloud(partial_path), 2048)\n",
    "        complete_pc = self.random_sample(self.read_point_cloud(complete_path), 16384)\n",
    "        return torch.from_numpy(partial_pc), torch.from_numpy(complete_pc)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.complete_paths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = shapenet_data_loader(train_path_partial,train_path_complete,'train')\n",
    "valid_dataset = shapenet_data_loader(valid_path_partial,valid_path_complete,'valid')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataloader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=num_workers)\n",
    "val_dataloader = DataLoader(valid_dataset, batch_size=batch_size, shuffle=False, num_workers=num_workers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Partial point cloud shape: torch.Size([32, 2048, 3])\n",
      "Complete point cloud shape: torch.Size([32, 16384, 3])\n",
      "Partial point cloud data:\n",
      " tensor([[[-0.4167,  0.0941, -0.1277],\n",
      "         [ 0.4081, -0.0246,  0.0041],\n",
      "         [-0.2806,  0.0650, -0.0483],\n",
      "         ...,\n",
      "         [-0.1093,  0.0993,  0.0324],\n",
      "         [ 0.2152,  0.0170, -0.1987],\n",
      "         [ 0.0035,  0.0885, -0.0581]],\n",
      "\n",
      "        [[-0.0944,  0.0375, -0.1682],\n",
      "         [-0.1593,  0.0239, -0.1821],\n",
      "         [ 0.1941,  0.0355, -0.0192],\n",
      "         ...,\n",
      "         [-0.1544,  0.1119, -0.0133],\n",
      "         [-0.2323,  0.0969, -0.0133],\n",
      "         [-0.0539,  0.0860, -0.1232]],\n",
      "\n",
      "        [[ 0.0284, -0.0261, -0.0910],\n",
      "         [ 0.2929, -0.0181, -0.1575],\n",
      "         [-0.3045, -0.0028, -0.1551],\n",
      "         ...,\n",
      "         [-0.4459,  0.0548, -0.0710],\n",
      "         [-0.0527,  0.0199, -0.0837],\n",
      "         [-0.3080,  0.0521, -0.0008]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ 0.0650,  0.0217, -0.1716],\n",
      "         [-0.0277,  0.1708, -0.1368],\n",
      "         [ 0.1003,  0.0872, -0.1915],\n",
      "         ...,\n",
      "         [-0.1615, -0.0921,  0.1387],\n",
      "         [ 0.1900, -0.0126, -0.1566],\n",
      "         [ 0.2370, -0.0579, -0.1871]],\n",
      "\n",
      "        [[ 0.3491,  0.0482,  0.0388],\n",
      "         [-0.0983, -0.0122, -0.1624],\n",
      "         [-0.4124,  0.0298, -0.0196],\n",
      "         ...,\n",
      "         [-0.2838,  0.0157,  0.1836],\n",
      "         [-0.1859,  0.0976, -0.0971],\n",
      "         [ 0.1936,  0.0038,  0.1771]],\n",
      "\n",
      "        [[-0.2596,  0.1555,  0.0403],\n",
      "         [ 0.1252,  0.1110, -0.1488],\n",
      "         [-0.2793,  0.1500, -0.0038],\n",
      "         ...,\n",
      "         [-0.2845, -0.0237, -0.1746],\n",
      "         [-0.2954,  0.0135, -0.1965],\n",
      "         [-0.2653,  0.1516, -0.0635]]])\n",
      "Complete point cloud data:\n",
      " tensor([[[ 0.2500, -0.0203, -0.1908],\n",
      "         [-0.2008,  0.0141, -0.1776],\n",
      "         [ 0.2619,  0.0042,  0.1862],\n",
      "         ...,\n",
      "         [ 0.0705,  0.0083, -0.1708],\n",
      "         [-0.2947, -0.0593,  0.1945],\n",
      "         [-0.3280, -0.0601,  0.1609]],\n",
      "\n",
      "        [[ 0.2609, -0.0797,  0.1786],\n",
      "         [-0.3350, -0.0201, -0.0925],\n",
      "         [-0.0362, -0.0945, -0.1465],\n",
      "         ...,\n",
      "         [ 0.4141, -0.0518, -0.0094],\n",
      "         [-0.3578, -0.0390, -0.1106],\n",
      "         [-0.1408, -0.0964,  0.0304]],\n",
      "\n",
      "        [[ 0.2613, -0.0418,  0.0773],\n",
      "         [ 0.2296, -0.0488, -0.1047],\n",
      "         [-0.0828,  0.0149, -0.0664],\n",
      "         ...,\n",
      "         [-0.4403,  0.0217, -0.0703],\n",
      "         [-0.3454, -0.0766,  0.0320],\n",
      "         [-0.3494, -0.0161,  0.0073]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[-0.3188, -0.1099, -0.1356],\n",
      "         [ 0.1201, -0.0705,  0.1433],\n",
      "         [ 0.2785, -0.1298, -0.1708],\n",
      "         ...,\n",
      "         [-0.2028, -0.1055,  0.1813],\n",
      "         [ 0.3161,  0.0733, -0.0373],\n",
      "         [ 0.2940, -0.1057, -0.0668]],\n",
      "\n",
      "        [[-0.0958,  0.1203,  0.0190],\n",
      "         [-0.3211,  0.0099, -0.1874],\n",
      "         [ 0.3595,  0.0249, -0.1257],\n",
      "         ...,\n",
      "         [ 0.4113, -0.0594,  0.0237],\n",
      "         [ 0.0372,  0.0054,  0.1644],\n",
      "         [ 0.2703, -0.1159, -0.1373]],\n",
      "\n",
      "        [[-0.3987,  0.0709, -0.0371],\n",
      "         [-0.3774,  0.0755,  0.0530],\n",
      "         [-0.2877, -0.0225,  0.1422],\n",
      "         ...,\n",
      "         [ 0.2150,  0.0625, -0.0745],\n",
      "         [-0.2612, -0.0848, -0.1635],\n",
      "         [ 0.3609,  0.0362, -0.1110]]])\n"
     ]
    }
   ],
   "source": [
    "for partial_pc, complete_pc in train_dataloader:\n",
    "    print(\"Partial point cloud shape:\", partial_pc.shape)   \n",
    "    print(\"Complete point cloud shape:\", complete_pc.shape) \n",
    "    print(\"Partial point cloud data:\\n\", partial_pc)        \n",
    "    print(\"Complete point cloud data:\\n\", complete_pc)\n",
    "    break  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PCN(nn.Module):\n",
    "    def __init__(self, num_dense=16384, latent_dim=1024, grid_size=4):\n",
    "        super().__init__()\n",
    "        self.num_dense = num_dense\n",
    "        self.latent_dim = latent_dim\n",
    "        self.grid_size = grid_size\n",
    "        assert self.num_dense % self.grid_size ** 2 == 0\n",
    "        self.num_coarse = self.num_dense // (self.grid_size ** 2)\n",
    "        self.first_conv = nn.Sequential(nn.Conv1d(3, 128, 1),nn.BatchNorm1d(128),nn.ReLU(inplace=True),nn.Conv1d(128, 256, 1))\n",
    "        self.second_conv = nn.Sequential(nn.Conv1d(512, 512, 1),nn.BatchNorm1d(512),nn.ReLU(inplace=True),nn.Conv1d(512, self.latent_dim, 1))\n",
    "        self.mlp = nn.Sequential(\n",
    "            nn.Linear(self.latent_dim, 1024),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Linear(1024, 1024),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Linear(1024, 3 * self.num_coarse)\n",
    "        )\n",
    "\n",
    "        self.final_conv = nn.Sequential(\n",
    "            nn.Conv1d(1024 + 3 + 2, 512, 1),\n",
    "            nn.BatchNorm1d(512),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv1d(512, 512, 1),\n",
    "            nn.BatchNorm1d(512),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv1d(512, 3, 1)\n",
    "        )\n",
    "        a = torch.linspace(-0.05, 0.05, steps=self.grid_size, dtype=torch.float).view(1, self.grid_size).expand(self.grid_size, self.grid_size).reshape(1, -1)\n",
    "        b = torch.linspace(-0.05, 0.05, steps=self.grid_size, dtype=torch.float).view(self.grid_size, 1).expand(self.grid_size, self.grid_size).reshape(1, -1)\n",
    "        \n",
    "        self.folding_seed = torch.cat([a, b], dim=0).view(1, 2, self.grid_size ** 2).cuda()  # (1, 2, S)\n",
    "\n",
    "    def forward(self, xyz):\n",
    "        B, N, _ = xyz.shape\n",
    "        \n",
    "        # encoder\n",
    "        feature = self.first_conv(xyz.transpose(2, 1))                                       # (B,  256, N)\n",
    "        feature_global = torch.max(feature, dim=2, keepdim=True)[0]                          # (B,  256, 1)\n",
    "        feature = torch.cat([feature_global.expand(-1, -1, N), feature], dim=1)              # (B,  512, N)\n",
    "        feature = self.second_conv(feature)                                                  # (B, 1024, N)\n",
    "        feature_global = torch.max(feature,dim=2,keepdim=False)[0]                           # (B, 1024)\n",
    "        \n",
    "        # decoder\n",
    "        coarse = self.mlp(feature_global).reshape(-1, self.num_coarse, 3)                    # (B, num_coarse, 3), coarse point cloud\n",
    "        point_feat = coarse.unsqueeze(2).expand(-1, -1, self.grid_size ** 2, -1)             # (B, num_coarse, S, 3)\n",
    "        point_feat = point_feat.reshape(-1, self.num_dense, 3).transpose(2, 1)               # (B, 3, num_fine)\n",
    "\n",
    "        seed = self.folding_seed.unsqueeze(2).expand(B, -1, self.num_coarse, -1)             # (B, 2, num_coarse, S)\n",
    "        seed = seed.reshape(B, -1, self.num_dense)                                           # (B, 2, num_fine)\n",
    "\n",
    "        feature_global = feature_global.unsqueeze(2).expand(-1, -1, self.num_dense)          # (B, 1024, num_fine)\n",
    "        feat = torch.cat([feature_global, seed, point_feat], dim=1)                          # (B, 1024+2+3, num_fine)\n",
    "    \n",
    "        fine = self.final_conv(feat) + point_feat                                            # (B, 3, num_fine), fine point cloud\n",
    "\n",
    "        return coarse.contiguous(), fine.transpose(1, 2).contiguous()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = PCN(num_dense=16384, latent_dim=1024, grid_size=4).to(device)\n",
    "optimizer = Optim.Adam(model.parameters(), lr=LR, betas=(0.9, 0.999))\n",
    "lr_schedual = Optim.lr_scheduler.StepLR(optimizer, step_size=50, gamma=0.7)\n",
    "step = len(train_dataloader) // 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_cd_l1 = 1e8\n",
    "best_epoch_l1 = -1\n",
    "train_step, val_step = 0, 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ananthakrishnak/miniconda3/envs/pcn/lib/python3.10/site-packages/torch/utils/cpp_extension.py:1965: UserWarning: TORCH_CUDA_ARCH_LIST is not set, all archs for visible cards are included for compilation. \n",
      "If this is not desired, please set os.environ['TORCH_CUDA_ARCH_LIST'].\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from torch.autograd import Function\n",
    "\n",
    "from torch.utils.cpp_extension import load\n",
    "\n",
    "# cudapath = rf''\n",
    "chamfer_3D = load(name=\"chamfer_3D\",\n",
    "sources=[rf\"/home/ananthakrishnak/pe/pcn-our/chamfer_cuda.cpp\",\n",
    "         rf\"/home/ananthakrishnak/pe/pcn-our/chamfer3D.cu\",\n",
    "        ])\n",
    "\n",
    "class chamfer_3DFunction(Function):\n",
    "    @staticmethod\n",
    "    def forward(ctx, xyz1, xyz2):\n",
    "        \"\"\"\n",
    "        xyz1: (B, N, 3)\n",
    "        xyz2: (B, M, 3)\n",
    "        \"\"\"\n",
    "        batchsize, n, _ = xyz1.size()\n",
    "        _, m, _ = xyz2.size()\n",
    "        device = xyz1.device\n",
    "\n",
    "        dist1 = torch.zeros(batchsize, n)\n",
    "        dist2 = torch.zeros(batchsize, m)\n",
    "\n",
    "        idx1 = torch.zeros(batchsize, n).type(torch.IntTensor)\n",
    "        idx2 = torch.zeros(batchsize, m).type(torch.IntTensor)\n",
    "\n",
    "        dist1 = dist1.to(device)\n",
    "        dist2 = dist2.to(device)\n",
    "        idx1 = idx1.to(device)\n",
    "        idx2 = idx2.to(device)\n",
    "        torch.cuda.set_device(device)\n",
    "\n",
    "        chamfer_3D.forward(xyz1, xyz2, dist1, dist2, idx1, idx2)\n",
    "        ctx.save_for_backward(xyz1, xyz2, idx1, idx2)\n",
    "        return dist1, dist2, idx1, idx2\n",
    "\n",
    "    @staticmethod\n",
    "    def backward(ctx, graddist1, graddist2, gradidx1, gradidx2):\n",
    "        xyz1, xyz2, idx1, idx2 = ctx.saved_tensors\n",
    "        graddist1 = graddist1.contiguous()\n",
    "        graddist2 = graddist2.contiguous()\n",
    "        device = graddist1.device\n",
    "\n",
    "        gradxyz1 = torch.zeros(xyz1.size())\n",
    "        gradxyz2 = torch.zeros(xyz2.size())\n",
    "\n",
    "        gradxyz1 = gradxyz1.to(device)\n",
    "        gradxyz2 = gradxyz2.to(device)\n",
    "        chamfer_3D.backward(\n",
    "            xyz1, xyz2, gradxyz1, gradxyz2, graddist1, graddist2, idx1, idx2\n",
    "        )\n",
    "        return gradxyz1, gradxyz2\n",
    "\n",
    "class ChamferDistance(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(ChamferDistance, self).__init__()\n",
    "\n",
    "    def forward(self, input1, input2):\n",
    "        \"\"\"\n",
    "        input1: (B, N, 3)\n",
    "        input2: (B, M, 3)\n",
    "        \"\"\"\n",
    "        dist1, dist2, _, _ = chamfer_3DFunction.apply(input1, input2)\n",
    "        return dist1, dist2\n",
    "    \n",
    "CD = ChamferDistance()\n",
    "\n",
    "def cd_loss_L1(pcs1, pcs2):\n",
    "    \"\"\"\n",
    "    L1 Chamfer Distance.\n",
    "\n",
    "    Args:\n",
    "        pcs1 (torch.tensor): (B, N, 3)\n",
    "        pcs2 (torch.tensor): (B, M, 3)\n",
    "    \"\"\"\n",
    "    dist1, dist2 = CD(pcs1, pcs2)\n",
    "    dist1 = torch.sqrt(dist1)\n",
    "    dist2 = torch.sqrt(dist2)\n",
    "    return (torch.mean(dist1) + torch.mean(dist2)) / 2.0\n",
    "\n",
    "\n",
    "def l1_cd(pcs1, pcs2):\n",
    "    dist1, dist2 = CD(pcs1, pcs2)\n",
    "    dist1 = torch.mean(torch.sqrt(dist1), 1)\n",
    "    dist2 = torch.mean(torch.sqrt(dist2), 1)\n",
    "    return torch.sum(dist1 + dist2) / 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Epoch [001/100] - Iteration [003/178]: coarse loss = 38.733978, dense l1 cd = 277.779400, total loss = 41.511770\n",
      "Training Epoch [001/100] - Iteration [006/178]: coarse loss = 28.575195, dense l1 cd = 299.597621, total loss = 31.571172\n",
      "Training Epoch [001/100] - Iteration [009/178]: coarse loss = 27.415337, dense l1 cd = 186.357304, total loss = 29.278910\n",
      "Training Epoch [001/100] - Iteration [012/178]: coarse loss = 24.528857, dense l1 cd = 171.646833, total loss = 26.245326\n",
      "Training Epoch [001/100] - Iteration [015/178]: coarse loss = 22.349451, dense l1 cd = 158.647418, total loss = 23.935925\n",
      "Training Epoch [001/100] - Iteration [018/178]: coarse loss = 22.402264, dense l1 cd = 228.538513, total loss = 24.687650\n",
      "Training Epoch [001/100] - Iteration [021/178]: coarse loss = 22.459216, dense l1 cd = 179.381251, total loss = 24.253029\n",
      "Training Epoch [001/100] - Iteration [024/178]: coarse loss = 21.353427, dense l1 cd = 158.186585, total loss = 22.935294\n",
      "Training Epoch [001/100] - Iteration [027/178]: coarse loss = 20.685647, dense l1 cd = 159.478948, total loss = 22.280436\n",
      "Training Epoch [001/100] - Iteration [030/178]: coarse loss = 20.335050, dense l1 cd = 131.621838, total loss = 21.651268\n",
      "Training Epoch [001/100] - Iteration [033/178]: coarse loss = 21.005275, dense l1 cd = 145.332515, total loss = 22.458600\n",
      "Training Epoch [001/100] - Iteration [036/178]: coarse loss = 22.796983, dense l1 cd = 153.678507, total loss = 24.333768\n",
      "Training Epoch [001/100] - Iteration [039/178]: coarse loss = 20.276573, dense l1 cd = 158.348382, total loss = 21.860056\n",
      "Training Epoch [001/100] - Iteration [042/178]: coarse loss = 19.545350, dense l1 cd = 101.960778, total loss = 20.564958\n",
      "Training Epoch [001/100] - Iteration [045/178]: coarse loss = 19.127060, dense l1 cd = 139.363050, total loss = 20.520691\n",
      "Training Epoch [001/100] - Iteration [048/178]: coarse loss = 19.958604, dense l1 cd = 125.132591, total loss = 21.209929\n",
      "Training Epoch [001/100] - Iteration [051/178]: coarse loss = 19.585509, dense l1 cd = 109.969318, total loss = 20.685202\n",
      "Training Epoch [001/100] - Iteration [054/178]: coarse loss = 18.531092, dense l1 cd = 107.658669, total loss = 19.607678\n",
      "Training Epoch [001/100] - Iteration [057/178]: coarse loss = 19.247634, dense l1 cd = 133.071005, total loss = 20.578343\n",
      "Training Epoch [001/100] - Iteration [060/178]: coarse loss = 20.956257, dense l1 cd = 123.578474, total loss = 22.192042\n",
      "Training Epoch [001/100] - Iteration [063/178]: coarse loss = 19.127607, dense l1 cd = 100.774787, total loss = 20.135354\n",
      "Training Epoch [001/100] - Iteration [066/178]: coarse loss = 19.979903, dense l1 cd = 94.987169, total loss = 20.929774\n",
      "Training Epoch [001/100] - Iteration [069/178]: coarse loss = 18.786542, dense l1 cd = 81.027672, total loss = 19.596819\n",
      "Training Epoch [001/100] - Iteration [072/178]: coarse loss = 21.594271, dense l1 cd = 93.682572, total loss = 22.531096\n",
      "Training Epoch [001/100] - Iteration [075/178]: coarse loss = 18.440187, dense l1 cd = 95.007606, total loss = 19.390263\n",
      "Training Epoch [001/100] - Iteration [078/178]: coarse loss = 18.230831, dense l1 cd = 81.279397, total loss = 19.043624\n",
      "Training Epoch [001/100] - Iteration [081/178]: coarse loss = 18.647049, dense l1 cd = 93.508944, total loss = 19.582137\n",
      "Training Epoch [001/100] - Iteration [084/178]: coarse loss = 19.259125, dense l1 cd = 65.703586, total loss = 19.916160\n",
      "Training Epoch [001/100] - Iteration [087/178]: coarse loss = 18.781345, dense l1 cd = 82.146019, total loss = 19.602805\n",
      "Training Epoch [001/100] - Iteration [090/178]: coarse loss = 19.346174, dense l1 cd = 79.668835, total loss = 20.142863\n",
      "Training Epoch [001/100] - Iteration [093/178]: coarse loss = 18.756393, dense l1 cd = 84.499747, total loss = 19.601392\n",
      "Training Epoch [001/100] - Iteration [096/178]: coarse loss = 19.834353, dense l1 cd = 81.963956, total loss = 20.653993\n",
      "Training Epoch [001/100] - Iteration [099/178]: coarse loss = 20.624643, dense l1 cd = 74.968547, total loss = 21.374328\n",
      "Training Epoch [001/100] - Iteration [102/178]: coarse loss = 18.895699, dense l1 cd = 54.193459, total loss = 19.437633\n",
      "Training Epoch [001/100] - Iteration [105/178]: coarse loss = 19.115796, dense l1 cd = 73.927797, total loss = 19.855075\n",
      "Training Epoch [001/100] - Iteration [108/178]: coarse loss = 18.363805, dense l1 cd = 65.356761, total loss = 19.017372\n",
      "Training Epoch [001/100] - Iteration [111/178]: coarse loss = 18.506743, dense l1 cd = 69.087759, total loss = 19.197620\n",
      "Training Epoch [001/100] - Iteration [114/178]: coarse loss = 18.804785, dense l1 cd = 73.041856, total loss = 19.535203\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(1, epochs + 1):\n",
    "    # hyperparameter alpha\n",
    "    if train_step < 10000:\n",
    "        alpha = 0.01\n",
    "    elif train_step < 20000:\n",
    "        alpha = 0.1\n",
    "    elif train_step < 50000:\n",
    "        alpha = 0.5\n",
    "    else:\n",
    "        alpha = 1.0\n",
    "    \n",
    "    model.train()\n",
    "\n",
    "    for i, (p, c) in enumerate(train_dataloader):\n",
    "        p, c = p.to(device), c.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        coarse_pred, dense_pred = model(p)\n",
    "        loss1 = cd_loss_L1(coarse_pred, c)\n",
    "        loss2 = cd_loss_L1(dense_pred, c)\n",
    "        loss = loss1 + alpha * loss2\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        if (i + 1) % step == 0:\n",
    "            print(\"Training Epoch [{:03d}/{:03d}] - Iteration [{:03d}/{:03d}]: coarse loss = {:.6f}, dense l1 cd = {:.6f}, total loss = {:.6f}\".format(epoch, epochs, i + 1, len(train_dataloader), loss1.item() * 1e3, loss2.item() * 1e3, loss.item() * 1e3))\n",
    "        train_step += 1\n",
    "    lr_schedual.step()\n",
    "\n",
    "    # evaluation\n",
    "    model.eval()\n",
    "    total_cd_l1 = 0.0\n",
    "    with torch.no_grad():\n",
    "        rand_iter = random.randint(0, len(val_dataloader) - 1)  # for visualization\n",
    "\n",
    "        for i, (p, c) in enumerate(val_dataloader):\n",
    "            p, c = p.to(device), c.to(device)\n",
    "            coarse_pred, dense_pred = model(p)\n",
    "            total_cd_l1 += l1_cd(dense_pred, c).item()\n",
    "\n",
    "            # save into image\n",
    "            # if rand_iter == i:\n",
    "            #     index = random.randint(0, dense_pred.shape[0] - 1)\n",
    "            #     plot_pcd_one_view(os.path.join(epochs_dir, 'epoch_{:03d}.png'.format(epoch)),\n",
    "            #                         [p[index].detach().cpu().numpy(), coarse_pred[index].detach().cpu().numpy(), dense_pred[index].detach().cpu().numpy(), c[index].detach().cpu().numpy()],\n",
    "            #                         ['Input', 'Coarse', 'Dense', 'Ground Truth'], xlim=(-0.35, 0.35), ylim=(-0.35, 0.35), zlim=(-0.35, 0.35))\n",
    "        \n",
    "        total_cd_l1 /= len(valid_dataset)\n",
    "        val_step += 1\n",
    "    if total_cd_l1 < best_cd_l1:\n",
    "        best_epoch_l1 = epoch\n",
    "        best_cd_l1 = total_cd_l1\n",
    "        torch.save(model.state_dict(), os.path.join(rf\"/home/ananthakrishnak/pe/pcn-our/checkpoints\", 'best_l1_cd.pth'))\n",
    "\n",
    "\n",
    "    \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pcn",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
